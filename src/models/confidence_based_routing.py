"""
Enhanced Confidence-Based Routing System (Epic 1.16-1.20)
============================================================

This system implements intelligent routing decisions that combine:
1. High-confidence cached routing (similarity â‰¥0.92, accuracy â‰¥85%)
2. RAG-enhanced LLM analysis for complex cases
3. Comprehensive logging and monitoring for production analytics

Architecture:
- ConfidenceRouter: Main orchestrator for routing decisions
- AccuracyTracker: Historical accuracy metrics and caching
- RoutingLogger: Structured logging for analytics and monitoring
- PerformanceMonitor: Real-time metrics and dashboard data
"""

import asyncio
import json
import logging
import time
from datetime import datetime, UTC
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
from enum import Enum
import hashlib

# Add project root to path for imports
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))

from src.models.rag_intelligent_routing import (
    RAGIntelligentRouting,
    IntelligentSimilaritySearch
)

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class RoutingMethod(Enum):
    """Different routing methods available"""
    CACHED_ROUTE = "cached_route"           # High-confidence cached classification
    RAG_LLM = "rag_llm"                    # RAG-enhanced LLM analysis
    FALLBACK = "fallback"                   # Emergency fallback classification


@dataclass
class RoutingDecision:
    """Complete routing decision with evidence and metrics"""
    # Core decision
    ticket_id: str
    recommended_department: str
    confidence_score: float
    routing_method: RoutingMethod
    
    # Evidence and reasoning
    reasoning: str
    top_similarity_score: float
    historical_accuracy: Optional[float]
    cache_hit: bool
    
    # Performance metrics
    processing_time_ms: float
    timestamp: datetime
    
    # Supporting data
    similar_tickets_found: int
    confidence_threshold_met: bool
    accuracy_threshold_met: bool


class AccuracyTracker:
    """
    Track and manage historical accuracy metrics for cached routing decisions.
    
    In production, this would integrate with PostgreSQL to store and retrieve
    historical success rates per department, routing pattern, and time period.
    """
    
    def __init__(self):
        """Initialize accuracy tracking with mock data for demonstration"""
        
        # Mock historical accuracy data (in production: PostgreSQL queries)
        self.department_accuracy = {
            "technical_support_l1": {"total": 245, "correct": 201, "accuracy": 0.82},
            "technical_support_l2": {"total": 156, "correct": 142, "accuracy": 0.91},
            "billing_corrections": {"total": 189, "correct": 175, "accuracy": 0.93},
            "account_security": {"total": 134, "correct": 119, "accuracy": 0.89},
            "customer_feedback": {"total": 98, "correct": 87, "accuracy": 0.89},
            "network_operations": {"total": 67, "correct": 58, "accuracy": 0.87}
        }
        
        # Pattern-based accuracy (regex/keyword patterns)
        self.pattern_accuracy = {
            "billing_refund": {"accuracy": 0.94, "sample_size": 78},
            "login_security": {"accuracy": 0.91, "sample_size": 45},
            "network_outage": {"accuracy": 0.88, "sample_size": 34},
            "account_locked": {"accuracy": 0.96, "sample_size": 52}
        }
    
    async def get_department_accuracy(self, department: str) -> float:
        """Get historical accuracy for a specific department"""
        dept_stats = self.department_accuracy.get(department, {})
        return dept_stats.get("accuracy", 0.5)  # Default to 50% if unknown
    
    async def get_pattern_accuracy(self, pattern_id: str) -> float:
        """Get accuracy for a specific routing pattern"""
        pattern_stats = self.pattern_accuracy.get(pattern_id, {})
        return pattern_stats.get("accuracy", 0.5)
    
    async def update_accuracy(self, department: str, correct: bool):
        """Update accuracy metrics based on routing outcome"""
        if department not in self.department_accuracy:
            self.department_accuracy[department] = {"total": 0, "correct": 0, "accuracy": 0.5}
        
        stats = self.department_accuracy[department]
        stats["total"] += 1
        if correct:
            stats["correct"] += 1
        
        # Recalculate accuracy
        stats["accuracy"] = stats["correct"] / stats["total"] if stats["total"] > 0 else 0.5
        
        logger.info(f"Updated accuracy for {department}: {stats['accuracy']:.3f} ({stats['correct']}/{stats['total']})")


class RoutingLogger:
    """
    Structured logging system for routing decisions and analytics.
    
    Provides JSON-formatted logs suitable for ingestion into monitoring
    systems like ELK Stack, Splunk, or CloudWatch.
    """
    
    def __init__(self, log_file: str = "routing_decisions.jsonl"):
        """Initialize structured logging"""
        self.log_file = log_file
        
        # Configure JSON logger
        self.json_logger = logging.getLogger("routing_decisions")
        handler = logging.FileHandler(log_file)
        handler.setFormatter(logging.Formatter('%(message)s'))  # Raw JSON
        self.json_logger.addHandler(handler)
        self.json_logger.setLevel(logging.INFO)
    
    def log_routing_decision(self, decision: RoutingDecision, ticket_text: str = ""):
        """Log routing decision in structured JSON format"""
        
        log_entry = {
            "timestamp": decision.timestamp.isoformat(),
            "event_type": "routing_decision",
            "ticket_id": decision.ticket_id,
            
            # Core decision data
            "routing": {
                "department": decision.recommended_department,
                "confidence": decision.confidence_score,
                "method": decision.routing_method.value,
                "cache_hit": decision.cache_hit
            },
            
            # Evidence and metrics
            "evidence": {
                "top_similarity": decision.top_similarity_score,
                "historical_accuracy": decision.historical_accuracy,
                "similar_tickets": decision.similar_tickets_found,
                "reasoning": decision.reasoning
            },
            
            # Thresholds
            "thresholds": {
                "confidence_met": decision.confidence_threshold_met,
                "accuracy_met": decision.accuracy_threshold_met
            },
            
            # Performance
            "performance": {
                "processing_time_ms": decision.processing_time_ms
            },
            
            # Optional ticket data (truncated for privacy)
            "ticket": {
                "text_preview": ticket_text[:100] + "..." if len(ticket_text) > 100 else ticket_text,
                "text_length": len(ticket_text)
            }
        }
        
        # Log to JSON file
        self.json_logger.info(json.dumps(log_entry))
        
        # Log human-readable summary
        cache_status = "ğŸ¯ CACHE HIT" if decision.cache_hit else "ğŸ¤– LLM ANALYSIS"
        logger.info(f"{cache_status}: {decision.ticket_id} â†’ {decision.recommended_department} "
                   f"(confidence: {decision.confidence_score:.3f}, {decision.processing_time_ms:.1f}ms)")
    
    def log_cache_metrics(self, hit_rate: float, total_requests: int, cache_hits: int):
        """Log cache performance metrics"""
        
        log_entry = {
            "timestamp": datetime.now(UTC).isoformat(),
            "event_type": "cache_metrics",
            "cache": {
                "hit_rate": hit_rate,
                "total_requests": total_requests,
                "cache_hits": cache_hits,
                "cache_misses": total_requests - cache_hits
            }
        }
        
        self.json_logger.info(json.dumps(log_entry))
        logger.info(f"ğŸ“Š Cache Metrics: {hit_rate:.1%} hit rate ({cache_hits}/{total_requests})")


class PerformanceMonitor:
    """
    Real-time performance monitoring for routing system.
    
    Tracks metrics suitable for Grafana dashboards and alerting.
    """
    
    def __init__(self):
        """Initialize performance tracking"""
        self.metrics = {
            "total_requests": 0,
            "cache_hits": 0,
            "rag_llm_calls": 0,
            "fallback_calls": 0,
            
            # Performance metrics
            "avg_processing_time": 0.0,
            "processing_times": [],
            
            # Accuracy tracking
            "routing_accuracy": {},
            "confidence_distribution": {"high": 0, "medium": 0, "low": 0}
        }
    
    def record_routing_decision(self, decision: RoutingDecision):
        """Record metrics from a routing decision"""
        self.metrics["total_requests"] += 1
        
        # Route method tracking
        if decision.cache_hit:
            self.metrics["cache_hits"] += 1
        elif decision.routing_method == RoutingMethod.RAG_LLM:
            self.metrics["rag_llm_calls"] += 1
        else:
            self.metrics["fallback_calls"] += 1
        
        # Performance tracking
        self.metrics["processing_times"].append(decision.processing_time_ms)
        if len(self.metrics["processing_times"]) > 1000:  # Keep last 1000
            self.metrics["processing_times"] = self.metrics["processing_times"][-1000:]
        
        # Calculate rolling average
        self.metrics["avg_processing_time"] = sum(self.metrics["processing_times"]) / len(self.metrics["processing_times"])
        
        # Confidence distribution
        if decision.confidence_score >= 0.85:
            self.metrics["confidence_distribution"]["high"] += 1
        elif decision.confidence_score >= 0.70:
            self.metrics["confidence_distribution"]["medium"] += 1
        else:
            self.metrics["confidence_distribution"]["low"] += 1
    
    def get_cache_hit_rate(self) -> float:
        """Calculate current cache hit rate"""
        if self.metrics["total_requests"] == 0:
            return 0.0
        return self.metrics["cache_hits"] / self.metrics["total_requests"]
    
    def get_performance_summary(self) -> Dict[str, Any]:
        """Get comprehensive performance metrics"""
        hit_rate = self.get_cache_hit_rate()
        
        return {
            "cache_performance": {
                "hit_rate": hit_rate,
                "total_requests": self.metrics["total_requests"],
                "cache_hits": self.metrics["cache_hits"]
            },
            
            "routing_distribution": {
                "cached": self.metrics["cache_hits"],
                "rag_llm": self.metrics["rag_llm_calls"],
                "fallback": self.metrics["fallback_calls"]
            },
            
            "performance": {
                "avg_processing_time_ms": self.metrics["avg_processing_time"],
                "total_requests": self.metrics["total_requests"]
            },
            
            "confidence": self.metrics["confidence_distribution"]
        }


class ConfidenceBasedRouter:
    """
    Enhanced confidence-based routing system that combines cached routing
    with RAG-enhanced LLM analysis for optimal performance and accuracy.
    """
    
    def __init__(self, 
                 confidence_threshold: float = 0.92,
                 accuracy_threshold: float = 0.85):
        """
        Initialize confidence-based router.
        
        Args:
            confidence_threshold: Minimum similarity score for cached routing
            accuracy_threshold: Minimum historical accuracy for cached routing
        """
        self.confidence_threshold = confidence_threshold
        self.accuracy_threshold = accuracy_threshold
        
        # Core components
        self.rag_system = RAGIntelligentRouting()
        self.similarity_search = IntelligentSimilaritySearch()
        self.accuracy_tracker = AccuracyTracker()
        self.routing_logger = RoutingLogger()
        self.performance_monitor = PerformanceMonitor()
    
    def generate_ticket_id(self, ticket_text: str) -> str:
        """Generate consistent ticket ID from text"""
        hash_obj = hashlib.md5(ticket_text.encode())
        return f"TICKET-{hash_obj.hexdigest()[:8].upper()}"
    
    async def route_with_confidence(self, ticket_text: str) -> RoutingDecision:
        """
        Route ticket using confidence-based decision logic.
        
        Decision flow:
        1. Search for most similar historical ticket
        2. Check if similarity â‰¥ confidence_threshold AND accuracy â‰¥ accuracy_threshold
        3. If both met: return cached classification (cache hit)
        4. Otherwise: use RAG-enhanced LLM analysis
        """
        
        start_time = time.time()
        ticket_id = self.generate_ticket_id(ticket_text)
        
        try:
            # Step 1: Get top similar ticket for confidence analysis
            similar_tickets = await self.similarity_search.search_similar_tickets_with_routing(
                query_text=ticket_text,
                top_k=1  # Only need top match for confidence check
            )
            
            if not similar_tickets:
                # No similar tickets found - use RAG with empty context
                return await self._fallback_routing(ticket_id, ticket_text, start_time, "No similar tickets found")
            
            top_match = similar_tickets[0]
            top_similarity = top_match.similarity_score
            
            # Step 2: Get historical accuracy for the matched department
            if top_match.actual_department:
                historical_accuracy = await self.accuracy_tracker.get_department_accuracy(
                    top_match.actual_department
                )
            else:
                historical_accuracy = 0.0
            
            # Step 3: Apply confidence-based routing logic
            confidence_met = top_similarity >= self.confidence_threshold
            accuracy_met = historical_accuracy >= self.accuracy_threshold
            
            if confidence_met and accuracy_met:
                # HIGH CONFIDENCE: Use cached classification
                return await self._cached_routing(
                    ticket_id, ticket_text, top_match, historical_accuracy, start_time
                )
            else:
                # LOW CONFIDENCE: Use RAG-enhanced LLM analysis
                return await self._rag_llm_routing(
                    ticket_id, ticket_text, similar_tickets, historical_accuracy, start_time
                )
                
        except Exception as e:
            # Error fallback
            logger.error(f"Routing error for {ticket_id}: {e}")
            return await self._fallback_routing(
                ticket_id, ticket_text, start_time, f"Error: {str(e)}"
            )
    
    async def _cached_routing(self, ticket_id: str, ticket_text: str, 
                            top_match, historical_accuracy: float, start_time: float) -> RoutingDecision:
        """Handle cached routing decision"""
        
        processing_time = (time.time() - start_time) * 1000  # Convert to ms
        
        decision = RoutingDecision(
            ticket_id=ticket_id,
            recommended_department=top_match.actual_department,
            confidence_score=min(top_match.similarity_score + 0.1, 0.99),  # Boost cached confidence
            routing_method=RoutingMethod.CACHED_ROUTE,
            
            reasoning=f"Cached route: High similarity ({top_match.similarity_score:.3f}) "
                     f"with proven accuracy ({historical_accuracy:.1%})",
            top_similarity_score=top_match.similarity_score,
            historical_accuracy=historical_accuracy,
            cache_hit=True,
            
            processing_time_ms=processing_time,
            timestamp=datetime.now(UTC),
            
            similar_tickets_found=1,
            confidence_threshold_met=True,
            accuracy_threshold_met=True
        )
        
        # Log and track decision
        self.routing_logger.log_routing_decision(decision, ticket_text)
        self.performance_monitor.record_routing_decision(decision)
        
        return decision
    
    async def _rag_llm_routing(self, ticket_id: str, ticket_text: str,
                             similar_tickets: List, historical_accuracy: float, 
                             start_time: float) -> RoutingDecision:
        """Handle RAG-enhanced LLM routing"""
        
        # Use existing RAG system for enhanced analysis
        rag_result = await self.rag_system.route_ticket_intelligently(ticket_text)
        
        processing_time = (time.time() - start_time) * 1000
        
        decision = RoutingDecision(
            ticket_id=ticket_id,
            recommended_department=rag_result["recommended_department"],
            confidence_score=self._parse_confidence(rag_result.get("confidence_level", "medium")),
            routing_method=RoutingMethod.RAG_LLM,
            
            reasoning=f"RAG-LLM: {rag_result.get('reasoning', 'Enhanced analysis with historical context')}",
            top_similarity_score=rag_result.get("top_similarity_score", 0.0),
            historical_accuracy=historical_accuracy,
            cache_hit=False,
            
            processing_time_ms=processing_time,
            timestamp=datetime.now(UTC),
            
            similar_tickets_found=len(similar_tickets),
            confidence_threshold_met=False,
            accuracy_threshold_met=historical_accuracy >= self.accuracy_threshold
        )
        
        # Log and track decision
        self.routing_logger.log_routing_decision(decision, ticket_text)
        self.performance_monitor.record_routing_decision(decision)
        
        return decision
    
    async def _fallback_routing(self, ticket_id: str, ticket_text: str,
                              start_time: float, reason: str) -> RoutingDecision:
        """Handle fallback routing when other methods fail"""
        
        processing_time = (time.time() - start_time) * 1000
        
        # Simple fallback logic based on keywords
        fallback_dept = self._simple_keyword_routing(ticket_text)
        
        decision = RoutingDecision(
            ticket_id=ticket_id,
            recommended_department=fallback_dept,
            confidence_score=0.50,  # Low confidence for fallback
            routing_method=RoutingMethod.FALLBACK,
            
            reasoning=f"Fallback routing: {reason}",
            top_similarity_score=0.0,
            historical_accuracy=None,
            cache_hit=False,
            
            processing_time_ms=processing_time,
            timestamp=datetime.now(UTC),
            
            similar_tickets_found=0,
            confidence_threshold_met=False,
            accuracy_threshold_met=False
        )
        
        # Log and track decision
        self.routing_logger.log_routing_decision(decision, ticket_text)
        self.performance_monitor.record_routing_decision(decision)
        
        return decision
    
    def _parse_confidence(self, confidence_str: str) -> float:
        """Convert confidence string to numeric score"""
        confidence_map = {"high": 0.90, "medium": 0.75, "low": 0.60}
        return confidence_map.get(confidence_str.lower(), 0.75)
    
    def _simple_keyword_routing(self, ticket_text: str) -> str:
        """Simple keyword-based fallback routing"""
        text_lower = ticket_text.lower()
        
        if any(word in text_lower for word in ["bill", "charge", "refund", "payment"]):
            return "billing_corrections"
        elif any(word in text_lower for word in ["login", "password", "account", "security"]):
            return "account_security"
        elif any(word in text_lower for word in ["internet", "connection", "network", "outage"]):
            return "technical_support_l1"
        elif any(word in text_lower for word in ["thank", "excellent", "great", "satisfied"]):
            return "customer_feedback"
        else:
            return "customer_support_general"
    
    def get_performance_metrics(self) -> Dict[str, Any]:
        """Get comprehensive performance metrics"""
        return self.performance_monitor.get_performance_summary()


async def test_confidence_routing_system():
    """Test the complete confidence-based routing system"""
    
    print("ğŸ¯ Testing Enhanced Confidence-Based Routing System")
    print("=" * 55)
    
    router = ConfidenceBasedRouter(
        confidence_threshold=0.85,  # Slightly lower for demo
        accuracy_threshold=0.80
    )
    
    # Test scenarios with varying confidence levels
    test_cases = [
        {
            "text": "My internet connection keeps dropping during video calls with clients",
            "expected_method": "rag_llm",  # Should trigger LLM analysis
            "category": "Technical Issue (Complex)"
        },
        {
            "text": "I need a refund for duplicate billing charges on my account",
            "expected_method": "cached_route",  # High confidence billing pattern
            "category": "Billing Issue (Clear)"
        },
        {
            "text": "Cannot access my account, getting authentication errors",
            "expected_method": "rag_llm",  # Security issue needs analysis
            "category": "Security Issue (Analysis Required)"
        },
        {
            "text": "Thanks for the excellent customer service, issue resolved!",
            "expected_method": "cached_route",  # Clear positive feedback
            "category": "Customer Feedback (Positive)"
        }
    ]
    
    print("\nğŸ”§ Router Configuration:")
    print(f"   Confidence Threshold: {router.confidence_threshold}")
    print(f"   Accuracy Threshold: {router.accuracy_threshold}")
    
    results = []
    
    for i, test in enumerate(test_cases, 1):
        print(f"\nğŸ¯ Test Case {i}: {test['category']}")
        print(f"ğŸ“ Ticket: '{test['text'][:60]}...'")
        
        # Route with confidence analysis
        decision = await router.route_with_confidence(test['text'])
        
        print("\nğŸ“Š ROUTING DECISION:")
        print(f"   ğŸ¯ Department: {decision.recommended_department}")
        print(f"   ğŸ“ˆ Confidence: {decision.confidence_score:.3f}")
        print(f"   ğŸ”„ Method: {decision.routing_method.value}")
        print(f"   âš¡ Processing Time: {decision.processing_time_ms:.1f}ms")
        print(f"   ğŸ¯ Cache Hit: {'âœ… YES' if decision.cache_hit else 'âŒ NO'}")
        
        print("\nğŸ“‹ EVIDENCE:")
        print(f"   ğŸ” Top Similarity: {decision.top_similarity_score:.3f}")
        if decision.historical_accuracy:
            print(f"   ğŸ“Š Historical Accuracy: {decision.historical_accuracy:.1%}")
        print(f"   ğŸ’­ Reasoning: {decision.reasoning}")
        
        # Validate expectations
        method_match = decision.routing_method.value == test.get("expected_method")
        expectation_symbol = "âœ…" if method_match else "âš ï¸"
        print(f"   {expectation_symbol} Expected Method: {test.get('expected_method', 'any')}")
        
        results.append({
            "case": test["category"],
            "method": decision.routing_method.value,
            "cache_hit": decision.cache_hit,
            "confidence": decision.confidence_score,
            "processing_time": decision.processing_time_ms
        })
    
    # Performance Summary
    print("\nğŸ“Š PERFORMANCE SUMMARY:")
    print("=" * 35)
    
    metrics = router.get_performance_metrics()
    cache_performance = metrics["cache_performance"]
    routing_dist = metrics["routing_distribution"]
    
    print(f"   Cache Hit Rate: {cache_performance['hit_rate']:.1%}")
    print(f"   Total Requests: {cache_performance['total_requests']}")
    print(f"   Avg Processing Time: {metrics['performance']['avg_processing_time_ms']:.1f}ms")
    
    print("\nğŸ”„ ROUTING DISTRIBUTION:")
    print(f"   Cached Routes: {routing_dist['cached']}")
    print(f"   RAG-LLM Analysis: {routing_dist['rag_llm']}")
    print(f"   Fallback Routes: {routing_dist['fallback']}")
    
    # Cache hit rate validation
    target_cache_rate = 0.25  # 25% target (adjustable based on data quality)
    actual_cache_rate = cache_performance['hit_rate']
    
    if actual_cache_rate >= target_cache_rate:
        print(f"\nâœ… CACHE PERFORMANCE: {actual_cache_rate:.1%} hit rate meets {target_cache_rate:.1%} target")
    else:
        print(f"\nâš ï¸ CACHE PERFORMANCE: {actual_cache_rate:.1%} hit rate below {target_cache_rate:.1%} target")
    
    return len(results) == len(test_cases)


async def run_confidence_routing_demo():
    """Run complete confidence-based routing demonstration"""
    
    print("ğŸš€ CONFIDENCE-BASED ROUTING SYSTEM DEMONSTRATION")
    print("Enhanced Hybrid Intelligence with Caching")
    print("=" * 60)
    
    try:
        # Test the complete system
        success = await test_confidence_routing_system()
        
        if success:
            print("\nğŸ‰ CONFIDENCE-BASED ROUTING SYSTEM COMPLETE!")
            print("\nğŸ’¡ KEY CAPABILITIES IMPLEMENTED:")
            print("   âœ… Intelligent similarity-based caching")
            print("   âœ… Historical accuracy tracking and validation")
            print("   âœ… Confidence-based routing decisions")
            print("   âœ… RAG-LLM integration for complex cases")
            print("   âœ… Comprehensive logging and monitoring")
            print("   âœ… Production-ready performance metrics")
            
            print("\nğŸ¯ PRODUCTION BENEFITS:")
            print("   âš¡ Faster responses via high-confidence caching")
            print("   ğŸ“Š Data-driven routing decisions")
            print("   ğŸ” Complete audit trail for all decisions")
            print("   ğŸ“ˆ Self-improving accuracy through feedback")
            
            return True
        else:
            print("\nâŒ Some tests failed. Review logs for details.")
            return False
            
    except Exception as e:
        print(f"\nâŒ Demonstration failed: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    print("Starting Enhanced Confidence-Based Routing Demonstration...")
    success = asyncio.run(run_confidence_routing_demo())
    
    if success:
        print("\nâœ… All demonstrations completed successfully!")
    else:
        print("\nâŒ Some demonstrations failed. Check logs for details.")